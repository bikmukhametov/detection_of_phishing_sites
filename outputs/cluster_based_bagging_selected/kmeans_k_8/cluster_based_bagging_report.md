# Cluster-Based Bagging на отобранных признаках (K=8)

Отчёт о сравнении sklearn и custom Bagging на явных и неясных кластерах из selected_pipeline.

## Стратегия

- **Данные**: новый датасет с отобранными признаками (new_dataset1.csv)
- **Кластеризация**: из outputs/selected_pipeline/kmeans_k_*
- **Обучающая выборка**: кластеры, где преобладает один класс (фишинг >80% или <20%)
- **Тестовая выборка**: кластеры с "неясной" композицией (20%-80% фишинга)
- **Явные кластеры**: [0, 1, 2, 4, 7]
- **Неясные кластеры**: [3, 5, 6]
- **Размер обучающей выборки**: 7084
- **Размер тестовой выборки**: 3971

## Результаты: Логистическая регрессия

| Реализация | Accuracy | Precision | Recall | F1 | ROC-AUC |
|---|---:|---:|---:|---:|---:|
| sklearn Bagging | 0.8330 | 0.8255 | 0.9505 | 0.8836 | 0.8909 |
| Custom Bagging | 0.8416 | 0.8397 | 0.9422 | 0.8880 | 0.8881 |

## Результаты: Дерево решений

| Реализация | Accuracy | Precision | Recall | F1 | ROC-AUC |
|---|---:|---:|---:|---:|---:|
| sklearn Bagging | 0.8142 | 0.8106 | 0.9411 | 0.8710 | 0.8845 |
| Custom Bagging | 0.8139 | 0.8124 | 0.9373 | 0.8704 | 0.8922 |

## Анализ

Модель была обучена на "явных" кластерах (отобранные признаки) и протестирована на "неясных" кластерах.
Это проверяет, насколько хорошо модель на отобранных признаках может классифицировать примеры на границе между фишингом и не-фишингом.

## Сохранённые файлы

- `bagging_metrics_lr.png` — сравнение метрик для логистической регрессии
- `bagging_metrics_dt.png` — сравнение метрик для дерева решений
- `cluster_based_bagging_report.md` — этот файл
