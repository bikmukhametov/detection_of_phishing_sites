# Cluster-Based Bagging на отобранных признаках (K=7)

Отчёт о сравнении sklearn и custom Bagging на явных и неясных кластерах из selected_pipeline.

## Стратегия

- **Данные**: новый датасет с отобранными признаками (new_dataset1.csv)
- **Кластеризация**: из outputs/selected_pipeline/kmeans_k_*
- **Обучающая выборка**: кластеры, где преобладает один класс (фишинг >80% или <20%)
- **Тестовая выборка**: кластеры с "неясной" композицией (20%-80% фишинга)
- **Явные кластеры**: [1, 2, 3, 5, 6]
- **Неясные кластеры**: [0, 4]
- **Размер обучающей выборки**: 7704
- **Размер тестовой выборки**: 3351

## Результаты: Логистическая регрессия

| Реализация | Accuracy | Precision | Recall | F1 | ROC-AUC |
|---|---:|---:|---:|---:|---:|
| sklearn Bagging | 0.8111 | 0.7934 | 0.9300 | 0.8563 | 0.8505 |
| Custom Bagging | 0.8081 | 0.7877 | 0.9349 | 0.8550 | 0.8514 |

## Результаты: Дерево решений

| Реализация | Accuracy | Precision | Recall | F1 | ROC-AUC |
|---|---:|---:|---:|---:|---:|
| sklearn Bagging | 0.7810 | 0.7543 | 0.9463 | 0.8395 | 0.8645 |
| Custom Bagging | 0.7914 | 0.7640 | 0.9482 | 0.8462 | 0.8812 |

## Анализ

Модель была обучена на "явных" кластерах (отобранные признаки) и протестирована на "неясных" кластерах.
Это проверяет, насколько хорошо модель на отобранных признаках может классифицировать примеры на границе между фишингом и не-фишингом.

## Сохранённые файлы

- `bagging_metrics_lr.png` — сравнение метрик для логистической регрессии
- `bagging_metrics_dt.png` — сравнение метрик для дерева решений
- `cluster_based_bagging_report.md` — этот файл
