# Сравнение Bagging

В этом отчёте сравниваются две пользовательские реализации базовых оценщиков: логистическая регрессия и дерево решений с использованием sklearn.BaggingClassifier и CustomBaggingClassifier.

## Результаты: Логистическая регрессия

| Реализация | Accuracy | Precision | Recall | F1 | ROC-AUC |
|---|---:|---:|---:|---:|---:|
| sklearn Bagging | 0.9285 | 0.9171 | 0.9583 | 0.9373 | 0.9819 |
| Custom Bagging | 0.9264 | 0.9100 | 0.9632 | 0.9358 | 0.9813 |

## Результаты: Дерево решений

| Реализация | Accuracy | Precision | Recall | F1 | ROC-AUC |
|---|---:|---:|---:|---:|---:|
| sklearn Bagging | 0.9334 | 0.9399 | 0.9404 | 0.9402 | 0.9841 |
| Custom Bagging | 0.9337 | 0.9222 | 0.9621 | 0.9417 | 0.9838 |

## Как работает sklearn.BaggingClassifier

`BaggingClassifier` из scikit-learn строит ансамбль базовых оценщиков, обучая каждый оценщик на случайно выбранной подвыборке объектов (и при необходимости — подвыборке признаков). Итоговое предсказание получается агрегированием прогнозов от всех оценщиков: усреднением вероятностей или большинством голосов.

Ключевые атрибуты:
- `estimators_` — список обученных оценщиков
- `estimators_features_` — индексы признаков, использованные каждым оценщиком (если `max_features` < 1)
- `oob_score_` — оценка вне выборки (если включено)

## Как работает пользовательский CustomBaggingClassifier

Пользовательская реализация выполняет следующие шаги:

- Для каждого из `n_estimators` создаётся случайная подвыборка образцов (по параметру `max_samples`) и подвыборка признаков (по параметру `max_features`).
- Клонируется переданный `base_estimator` и обучается на этой подвыборке.
- Сохраняется обученный оценщик и соответствующие индексы признаков.
- При предсказании усредняются предсказанные вероятности положительного класса от всех оценщиков; итоговое бинарное решение получается применением порога 0.5.

## Пример использования

```python
from src.bagging import CustomBaggingClassifier
clf = CustomBaggingClassifier(n_estimators=30, max_samples=0.8, max_features=0.6)
clf.fit(X_train, y_train)
pred = clf.predict(X_test)
proba = clf.predict_proba(X_test)[:, 1]
```

## Параметры и их влияние

- `n_estimators`: число базовых оценщиков; увеличение повышает стабильность, но увеличивает время обучения.
- `max_samples`: доля обучающих объектов, используемая для каждого оценщика; меньшие значения увеличивают разнообразие ансамбля.
- `max_features`: доля признаков, используемая для каждого оценщика; управляет разнообразием на уровне признаков.
- `bootstrap`: использовать ли выборку с возвращением для объектов.
- `bootstrap_features`: использовать ли выборку с возвращением для признаков.

## Рекомендации

- Для быстрых экспериментов рекомендуются `n_estimators=20..50`.
- Если в данных много признаков, снижение `max_features` (например, до 0.5) может повысить разнообразие и устойчивость модели.
- Для оценки можно включить `oob_score` в `sklearn.BaggingClassifier` и сравнить результаты с кросс-валидацией.

## Сохранённые файлы

- `bagging_metrics_lr.png` — столбчатая диаграмма сравнения метрик для логистической регрессии
- `bagging_metrics_dt.png` — столбчатая диаграмма сравнения метрик для дерева решений
- `bagging_summary.md` — этот файл
